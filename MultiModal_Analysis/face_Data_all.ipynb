{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중앙값으로 대체하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "out_path = r\"D:\\\\MultiModal\\\\MultiModal_Model\\\\results\\\\face\\\\face_landmark\\\\interpolate\"\n",
    "\n",
    "os.chdir(r\"D:\\\\MultiModal\\\\MultiModal_Model\\\\results\\\\face\\\\face_landmark\\\\C\\\\\")\n",
    "read_file = pd.read_excel(\"Face_1W_C1_S1.xlsx\", index_col=0)\n",
    "\n",
    "columns_to_interpolate = [\n",
    "    'right eye.x', 'right eye.y', 'left eye.x', 'left eye.y',\n",
    "    'nose.x', 'nose.y', 'mouse.x', 'mouse.y', \n",
    "    'right ear.x', 'right ear.y', 'left ear.x', 'left ear.y',\n",
    "    'box_origin.x', 'box_origin.y', 'box.width', 'box.height'\n",
    "]\n",
    "\n",
    "\n",
    "# 각 컬럼의 결측치를 중앙값으로 채움\n",
    "for column in columns_to_interpolate:\n",
    "    median_value = read_file[column].median()\n",
    "    read_file[column].fillna(median_value, inplace=True)\n",
    "\n",
    "#print(read_file)\n",
    "\n",
    "os.chdir(out_path)\n",
    "read_file.to_excel(\"Face_1W_C1_S1.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 기울기의 NaN 값을 보간할 수 있는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "out_path = r\"D:/MultiModal/MultiModal_Model/results/face/face_landmark/interpolate/C\"\n",
    "# D:\\MultiModal\\MultiModal_Model\\results\\face\\face_landmark\\interpolate\\C\n",
    "\n",
    "for week in [\"4W\"]: #4W\n",
    "    for group in [\"C1\", \"C2\", \"C3\", \"C4\"]:\n",
    "        # \"C1\", \"C2\", \"C3\", \"C4\", \"A1\", \"A2\", \"A3\", \"A4\"\n",
    "        for step in [\"S1\", \"S2\", \"S3\"]:\n",
    "            os.chdir(r\"D:\\\\MultiModal\\\\MultiModal_Model\\\\results\\\\face\\\\face_landmark\\\\C\")\n",
    "            \n",
    "            read_file = pd.read_excel(f\"Face_{week}_{group}_{step}.xlsx\", index_col=0)\n",
    "            # NaN 값이 있는 곳들을 보간하는 부분.\n",
    "\n",
    "            columns_to_interpolate = [\n",
    "            'right eye.x', 'right eye.y', 'left eye.x', 'left eye.y',\n",
    "            'nose.x', 'nose.y', 'mouse.x', 'mouse.y', \n",
    "            'right ear.x', 'right ear.y', 'left ear.x', 'left ear.y',\n",
    "            'box_origin.x', 'box_origin.y', 'box.width', 'box.height'\n",
    "            ]\n",
    "\n",
    "            # 각 컬럼의 결측치를 중앙값으로 채움\n",
    "            for column in columns_to_interpolate:\n",
    "                median_value = read_file[column].median()\n",
    "                read_file[column].fillna(median_value, inplace=True)\n",
    "            \n",
    "            # 보간된 값을 다시 엑셀로 내보내기. \n",
    "            os.chdir(out_path)\n",
    "            read_file.to_excel(f\"Face_{week}_{group}_{step}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face 값 중 너무 큰 값으로 튀는 outlier 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import seaborn as sns\n",
    "\n",
    "# 데이터 표준화를 위해 scipy.stats 라이브러리 사용\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이상치 제거 전, 불필요한 열을 제거하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list = [\"C\"] # A, D, E, F, G,\n",
    "# humans = [\"C1\", \"C2\", \"C3\", \"C4\"]\n",
    "\n",
    "#\"A1\", \"A2\", \"A3\", \"A4\"\n",
    "#\"B1\", \"B2\", \"B3\", \"B4\",\n",
    "#\"C1\", \"C2\", \"C3\", \"C4\",\n",
    "#\"D1\", \"D2\", \"D3\", \"D4\",\n",
    "#\"E1\", \"E2\", \"E3\", \"E4\",\n",
    "#\"F1\", \"F2\", \"F3\", \"F4\",\n",
    "#\"G1\", \"G2\", \"G3\", \"G4\"\n",
    "\n",
    "# 불필요한 열들을 제거한 후, 최종적으로 파일들을 저장해둘 경로.\n",
    "# for out in file_list:\n",
    "#     for week in [\"1W\", \"2W\", \"3W\", \"4W\"]:\n",
    "#         filtered_list = [human for human in humans if human.startswith(out)]\n",
    "#         for human in filtered_list:\n",
    "#             out_path = f\"D:/MultiModal/filtered_df/{out}/\" # 최종경로. \n",
    "#             # out_path = f\"D:/MultiModal/filtered_df/{out}/{steps}_{human}/\" # 최종경로. \n",
    "\n",
    "#             if not os.path.exists(out_path):\n",
    "#                 os.makedirs(out_path)\n",
    "                \n",
    "out_path = r\"D:/MultiModal/filtered_df/C/\"     \n",
    "                \n",
    "# face 파일들이 있는 구간.\n",
    "for files in [\"C\"]:\n",
    "    default_path = f\"D:/MultiModal/MultiModal_Model/results/face/face_landmark/interpolate/{files}/\"\n",
    "    path1 = os.listdir(default_path)\n",
    "    \n",
    "    # # path1 안에 들어 있는 '파일 명'만 있는 것이지 그 외는 아님. \n",
    "    for file in path1:\n",
    "        if '.xlsx' in file:\n",
    "            #print(file) # 파일명 출력해줌,. \n",
    "            full_path = os.path.join(default_path, file)\n",
    "            #print(full_path)\n",
    "            b_rotation = pd.read_excel(full_path)\n",
    "            #print(b_rotation)\n",
    "            filtered_df = b_rotation.drop(['right eye.x', 'right eye.y', 'left eye.x', 'left eye.y', 'nose.x', 'nose.y', 'mouse.x', 'mouse.y', 'right ear.x',\n",
    "                                        'right ear.y', 'left ear.x', 'left ear.y', 'box_origin.x', 'box_origin.y'], axis = 1)\n",
    "            \n",
    "            filtered_df.to_excel(os.path.join(out_path, f\"{file}\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이상치를 제거 코드 (파일 경로 접근 + 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier를 제거하는 부분 다시 해볼 것.\n",
    "\n",
    "# df = 데이터 프레임 넣기, column => outlier를 제거하기 위한 열 값 할당. z_score_threshold -> 기준 값 할당.\n",
    "def correct_outliers(df, column, z_score_threshold=2):\n",
    "    \n",
    "    mean = df[column].mean() ## 열 값에 해당하는 평균 \n",
    "    std = df[column].std() ## 열 값에 해당하는 std 값 구하기 .(std* 표준편차)\n",
    "\n",
    "    # Calculate the Z-scores\n",
    "    z_scores = (df[column] - mean) / std  ## 열 값이 평균으로 부터 얼만큼 일탈되었는가 (멀어져 있는가>? )\n",
    "\n",
    "    # z_score 값이 얼마인지 확인해볼 것. \n",
    "    print(z_scores)\n",
    "    \n",
    "    # Identify outliers\n",
    "    # Outlier 제거하는 부분에 있어서 과하게 짤린 것 같음. =========================================================================\n",
    "    outliers = abs(z_scores) > z_score_threshold ## 2보다 크면 많이 평균으로부터 많이 떨어져 있고, 매우 크거나 작다는 것을 의미. \n",
    "    #print(outliers)\n",
    "    # Replace outliers with the median of the column\n",
    "    median_value = df[column].median() ## 중앙값 구하기. \n",
    "    df.loc[outliers, column] = median_value ### df.loc() = median_value를 넣어줌. \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "steps = [\"1W\", \"2W\", \"3W\", \"4W\"]\n",
    "humans = [\"C1\", \"C2\", \"C3\", \"C4\"]\n",
    "\n",
    "#   \"A1\", \"A2\", \"A3\", \"A4\",\n",
    "#   \"B1\", \"B2\", \"B3\", \"B4\",\n",
    "#   \"C1\", \"C2\", \"C3\", \"C4\",\n",
    "#   \"D1\", \"D2\", \"D3\", \"D4\",\n",
    "#   \"E1\", \"E2\", \"E3\", \"E4\",\n",
    "#   \"F1\", \"F2\", \"F3\", \"F4\",\n",
    "#   \"G1\", \"G2\", \"G3\", \"G4\"          \n",
    "\n",
    "\n",
    "# load_path = \"D:/MultiModal/filtered_df/\"\n",
    "\n",
    "# for group in [\"A\"]:   # \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"\n",
    "#     for step in steps:\n",
    "#         filtered_human = [human for human in humans if human.startswith(group)]\n",
    "#         for human in filtered_human:\n",
    "#             dir \n",
    "#             if os.path.exists(load_path):\n",
    "#                 os.makedirs(load_path)\n",
    "\n",
    "\n",
    "for group in [\"C\"]:   # \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"\n",
    "    #for step in steps:\n",
    "        #filtered_human = [human for human in humans if human.startswith(group)]\n",
    "        #for human in filtered_human:\n",
    "\n",
    "    load_path = f\"D:/MultiModal/filtered_df/{group}/\"\n",
    "            \n",
    "    # 작업 디렉토리 가져오기. \n",
    "    file_list = os.listdir(load_path)\n",
    "    #print(file_list)\n",
    "    \n",
    "    output_folder = f\"D:/MultiModal/Face_z_score/C_1/\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file in file_list:\n",
    "        dir = os.path.join(load_path, file)\n",
    "        if dir.split('.')[-1] == \"xlsx\": \n",
    "            face_df = pd.read_excel(dir)\n",
    "\n",
    "            # 뽑아내고 싶은 열 이름 모음. \n",
    "            coordinate_columns = [\"box.width\", \"box.height\"]\n",
    "\n",
    "            for column in coordinate_columns:\n",
    "                # 뽑아낼 열 이름 넣어주고, 저장. \n",
    "                filtered_df = correct_outliers(face_df, column)\n",
    "                \n",
    "                #print(filtered_df)\n",
    "                # filtered_df 안에 값을 넣어서, 저장해줌. \n",
    "            #filtered_df.iloc[:, 1:].to_excel(output_folder + file.split('.')[0] + '.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아래 코드는 내가 직접 짜본 '데이터 정규화' 코드 || 문제점 : 정규화를 하는 것은 좋은데 값이 일부 날려보냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "steps = ['1W', '2W', '3W', '4W']\n",
    "humans = ['A1', 'A2', 'A3', 'A4',\n",
    "          'B1', 'B2', 'B3', 'B4',\n",
    "          'C1', 'C2', 'C3', 'C4',\n",
    "          'D1', 'D2', 'D3', 'D4',\n",
    "          'E1', 'E2', 'E3', 'E4',\n",
    "          'F1', 'F2', 'F3', 'F4',\n",
    "          'G1', 'G2', 'G3', 'G4']\n",
    "\n",
    "# 저장할 수 있는 경로 설정.\n",
    "for group in groups:\n",
    "    for step in steps:\n",
    "        for human in humans:\n",
    "            result_out_path = f\"D:/MultiModal/Face_z_score/{group}/{step}_{human}/\"\n",
    "            if not os.path.exists(result_out_path):\n",
    "                os.makedirs(result_out_path)\n",
    "\n",
    "# 경로 설정 \n",
    "for group in groups:\n",
    "    for step in steps:\n",
    "        for human in humans:\n",
    "            face_file_path = f\"D:/MultiModal/filtered_df/{group}/{step}_{human}/\"\n",
    "            \n",
    "            if os.path.exists(face_file_path):\n",
    "                files = os.listdir(face_file_path)\n",
    "                # 엑셀 파일들 리스트 출력하기\n",
    "                #print(files)     \n",
    "                \n",
    "                # files -> listdir()를 통해서 list 형태로 있는 값들을 불러온 것. \n",
    "                for i in files:\n",
    "                    full_path1 = os.path.join(face_file_path, i) # 경로에 있는 값 하나씩 불러오기. \n",
    "                    temp_file = pd.read_excel(full_path1) # 하나씩 불러왔으니, 이를 읽기 위해 read_excel 사용. \n",
    "                    #print(temp_file)\n",
    "            \n",
    "                    # 이상치를 구하기 위한 식) : (값 - 평균) / (표준편차)  => z_score 값\n",
    "                    outlier_face = temp_file[(abs((temp_file['box.height'] - np.mean(temp_file['box.height'])) / np.std(temp_file['box.height']))) > 1.96].index\n",
    "                    # 이상치로 판단되는 값을 제거. \n",
    "                    new_df = temp_file.drop(outlier_face)\n",
    "                    #print(new_df)\n",
    "                    \n",
    "                    #이상치를 제거했다면, 결과 값을 엑셀에 저장. \n",
    "                    new_df.to_excel(os.path.join(result_out_path, f\"filtered_outlier_{i}\"), index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 델타 값 계산해서, 그래프 그리기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# body_lean_delta 값 계산\n",
    "body_path = \"D:\\\\MultiModal\\\\body_lean_all\\\\F\\\\\"\n",
    "# B,C,D,E,F,G\n",
    "\n",
    "# face_lean_delta 값 계산\n",
    "face_path = \"D:/MultiModal/filtered_df/F/\"\n",
    "# B,C,D,E,F,G\n",
    "\n",
    "out_path = \"D:/MultiModal/data_visualize/F/\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path) \n",
    "\n",
    "# 각각 뽑아봐야 하는 것들. \n",
    "steps = ['4W'] # '2W', '3W', '4W'\n",
    "humans = ['F1']\n",
    "# 'A2', 'A3', 'A4'\n",
    "\n",
    "for step in steps:\n",
    "    for human in humans:\n",
    "        dir = os.path.join(face_path, f\"{step}_{human}\")\n",
    "        file_list = os.listdir(dir)\n",
    "        \n",
    "        dir_body = os.path.join(body_path, f\"{step}_{human}\")\n",
    "        file_body_list = os.listdir(dir_body)\n",
    "        \n",
    "        for file_b, files in zip(file_body_list, file_list):\n",
    "            file_zip_b = os.path.join(dir_body, file_b)\n",
    "            file_dir_b = pd.read_excel(file_zip_b)\n",
    "            \n",
    "            # body에서의 각 델타 값을 계산. \n",
    "            filtered_delta_b = file_dir_b.diff()\n",
    "            \n",
    "            # 그래프를 그리긱 전 NaN 값을 제거. *보간. \n",
    "            filtered_delta_b.interpolate(inplace=True)\n",
    "\n",
    "            # 차이 값이 계산되는지 확인. \n",
    "            #print(filtered_delta_b)\n",
    "            \n",
    "            file_zip = os.path.join(dir, files)\n",
    "            read_dir = pd.read_excel(file_zip)\n",
    "            \n",
    "            # 불필요한 열 제거. \n",
    "            read_dir.drop(['Unnamed: 0'], axis=1, inplace= True)\n",
    "            \n",
    "            # 각 델타 값들을 계산\n",
    "            filtered_delta = read_dir.diff()\n",
    "            print(filtered_delta) # 비교할 값이 없다면, NaN 값으로 출력. \n",
    "\n",
    "            # 그래프를 그리긱 전 NaN 값을 제거. \n",
    "            filtered_delta.interpolate(inplace=True)\n",
    "        \n",
    "            # 두 개의 데이터 프레임의 최소값을 맞춰주는 것.     \n",
    "            min_length = min(len(filtered_delta), len(filtered_delta_b))\n",
    "            filtered_delta = filtered_delta[:min_length]\n",
    "            filtered_delta_b = filtered_delta_b[:min_length]\n",
    "    \n",
    "            # 산점도를 확인해볼 수 있는 것. \n",
    "            #lt.scatter(filtered_delta, filtered_delta_b)\n",
    "            #plt.xlabel('body_lean')  # 바디 기울기.\n",
    "            #plt.ylabel('face_lean')  # 얼굴 기울기. \n",
    "            #plt.title('Scatter Plot of face_diff() vs. body_lean_diff()')\n",
    "            #plt.grid(True)  # Enable grid\n",
    "            #plt.show()\n",
    "        \n",
    "            new_df =  pd.concat([filtered_delta, filtered_delta_b], axis=1)\n",
    "            new_df.columns = ['filtered_delta', 'filtered_delta_b']\n",
    "            \n",
    "            # 뽑아보고 싶은 특정 열 선택. \n",
    "            data_range = new_df.loc[900:1000]\n",
    "            # Calculate the correlation matrix\n",
    "            correlation_matrix = new_df.corr()\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            plt.plot(data_range['filtered_delta'], label='filtered_delta')\n",
    "            plt.plot(data_range['filtered_delta_b'], label='filtered_delta_b')\n",
    "            plt.xlabel('Index')\n",
    "            plt.ylabel('Values')\n",
    "            plt.title('Graph of face box and body_lean (Index Range: 5100-5450)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "                    \n",
    "        \n",
    "        \n",
    "            # 히트 맵으로 보여주는 코드 부분\n",
    "            # 양의 상관 관계는 따뜻한 색상, 음의 상관관계는 파란색으로 나타남.\n",
    "            # 값이 1또는 -1에 가까울 수록 강한 상관관계를 나타내고, 0에 가까울수록 약한 상관 관계를 나타냄. \n",
    "            # Plotting heatmap of correlation matrix\n",
    "            # plt.figure(figsize=(8, 6))\n",
    "            # sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "            # plt.title('Correlation Heatmap between filtered_delta and filtered_delta_b')\n",
    "            # plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## face box scaling 해주는 구간."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "for group in [\"A\"]: #A\n",
    "    os.chdir(f\"D:/MultiModal/Face_z_score/{group}/\") \n",
    "    \n",
    "    ## D:\\MultiModal\\MultiModal_postprocessing\\results\\face\\face_landmark\\G\n",
    "    \n",
    "    # 파일 불러오기\n",
    "    file_list = os.listdir(os.getcwd())\n",
    "\n",
    "    # 출력할 파일 불러오기\n",
    "    output_folder = f\"D:/MultiModal/Face_z_score/Face_lean/{group}/\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # 컬럼명\n",
    "    face_landmark_col = [\"Week\", \"ID\", \"Step\", \"Face_lean_width\", \"Face_lean_height\"]\n",
    "\n",
    "    data = []\n",
    "    for file in file_list:\n",
    "        if file.split('.')[-1] == \"xlsx\":\n",
    "            landmark_df = pd.read_excel(file)\n",
    "            # scaling\n",
    "            landmark_df[\"lean_width\"] = min_max_scaling(landmark_df[\"box.width\"]) # 너비\n",
    "            landmark_df[\"lean_height\"] = min_max_scaling(landmark_df[\"box.height\"]) # 높이\n",
    "            \n",
    "            file_name = file.split('.')[0].split('_')\n",
    "            ## + '_' + file_name[-1]\n",
    "            data.append([file_name[1], file_name[2], file_name[3] if (file_name[3] == \"Baseline\" or file_name[3] == \"S3\") else file_name[3], np.mean(landmark_df[\"lean_width\"]), np.mean(landmark_df[\"lean_height\"])])\n",
    "\n",
    "    avg_box_df = pd.DataFrame(data, columns=face_landmark_col)\n",
    "    avg_box_df.to_excel(output_folder + f\"{group}_average_face_lean.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평균 Face lean 값을 정리하여 뽑아보는 구간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all df concat\n",
    "\n",
    "group_df = []\n",
    "\n",
    "for group in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "    os.chdir(f\"D:/MultiModal/Face_z_score/Face_lean/{group}/\") \n",
    "    ## D:\\MultiModal\\MultiModal_postprocessing\\results\\face_time\\face_landmark\\G\n",
    "    group_df.append(pd.read_excel(f\"{group}_average_face_lean.xlsx\").iloc[:, 1:])\n",
    "\n",
    "    output_folder = f\"../\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "all_group_df = pd.concat(group_df)\n",
    "all_group_df.to_excel(output_folder + \"All_average_face_lean(All group, anaysis).xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분석용으로 출력하는 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:/MultiModal/Face_z_score/Face_lean/\") \n",
    "all_df = pd.read_excel(\"All_average_face_lean(All group, anaysis).xlsx\") \n",
    "\n",
    "step_list = [\"S1\", \"S2\" \"S3\"]\n",
    "\n",
    "df_index = [\"Group\", \"ID\"] + [f\"{week}_{step}_Face_lean_{option}\" for week in [\"1W\", \"2W\", \"3W\", \"4W\"] for step in step_list for option in [\"width\", \"height\"]] \n",
    "\n",
    "data = []\n",
    "for group in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "    for id in [f\"{group}{id_index}\" for id_index in range(1, 5)]:\n",
    "        week_data = []\n",
    "        for week in [f\"{w_index}W\" for w_index in range(1, 5)]:\n",
    "            filtered_df = all_df[(all_df[\"Week\"] == week) & (all_df[\"ID\"] == id) & (all_df[\"Group\"] == group)]\n",
    "            print(filtered_df)\n",
    "            week_data.extend(filtered_df[[f\"{step}_Face_lean_{option}\" for step in step_list for option in [\"width\", \"height\"]]].values.flatten().tolist())\n",
    "        \n",
    "        data.append([group, id] + week_data)\n",
    "\n",
    "# all_summarize_df = pd.DataFrame(data, columns=df_index)\n",
    "# all_summarize_df.to_excel(\"All_average_face_lean(All group, excel_anaysis).xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 기울기 횟수 세는 구간."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 크기 변화량 값 계산하는 구간. \n",
    "def plus_minus(df):\n",
    "    df[\"box size\"] = df['box.width'] * df['box.height'] # 박스 사이즈 (얼굴 크기를 이야기 하는 것 )\n",
    "\n",
    "    W = \"box.width\"\n",
    "    H = \"box.height\"\n",
    "\n",
    "    df[\"box delta\"] = df[\"box size\"].diff() # 프레임 단위로 박스의 크기의 변화량을 체크\n",
    "    df_new = df.iloc[1:, :][\"box delta\"] # 첫 번째 행은 제외, 제외하지 않을 경우, 비교할 값이 없어서 NaN값 생성. \n",
    "    \n",
    "    # df_new 값일 어떻게 생성되는지 확인해보기 위해 출력. \n",
    "    #print(df_new)\n",
    "    \n",
    "    for i in range(len(df_new)):\n",
    "        \n",
    "        if(df_new.iloc[i] > 600):  # 평균적인 사이즈 값\n",
    "            df_new.iloc[i] = 1 # 앞으로 기울었을 때 \n",
    "        elif(df_new.iloc[i] < -600):\n",
    "            df_new.iloc[i] = -1 # 뒤로 기울었을 때 \n",
    "        else:\n",
    "            df_new.iloc[i] = 0 # 아무것도 아닐 때\n",
    "    return df_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 최종적으로 저장할 경로. \n",
    "data = []\n",
    "\n",
    "output_folder = f\"D:/MultiModal/Face_z_score/Face_lean_count/A/\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for group in [\"A\"]: # , \"B\",\"C\", \"D\", \"E\", \"F\", \"G\"\n",
    "    os.chdir(f\"D:/MultiModal/Face_z_score/{group}/\") \n",
    "\n",
    "    # 스텝에 나와 있는 것 \n",
    "    step_list = [\"S1\", \"S2\", \"S3\"]\n",
    "    #step_list = [\"S1_1\", \"S1_2\", \"S1_3\", \"S1_4\", \"S2_1\", \"S2_2\", \"S2_3\", \"S2_4\", \"S3\"]\n",
    "\n",
    "    face_index = [\"Group\", \"Week\",] + [f\"{step}_Face_lean_4p\" for step in step_list] + [f\"{step}_Face_lean_3p\" for step in step_list]\n",
    "\n",
    "    for week in [f\"{w_index}W\" for w_index in range(1, 5)]:\n",
    "        \n",
    "        step_data_4p = []\n",
    "        step_data = []\n",
    "        for step in step_list:\n",
    "            df1 = pd.read_excel(f'Face_{week}_{group}1_{step}.xlsx') if os.path.exists(f'Face_{week}_{group}1_{step}.xlsx') else []\n",
    "            df2 = pd.read_excel(f'Face_{week}_{group}2_{step}.xlsx') if os.path.exists(f'Face_{week}_{group}2_{step}.xlsx') else []\n",
    "            df3 = pd.read_excel(f'Face_{week}_{group}3_{step}.xlsx') if os.path.exists(f'Face_{week}_{group}3_{step}.xlsx') else []\n",
    "            df4 = pd.read_excel(f'Face_{week}_{group}4_{step}.xlsx') if os.path.exists(f'Face_{week}_{group}4_{step}.xlsx') else []\n",
    "            \n",
    "            #이상이 따로 없다면, df1~4까지의 len() 길이 값을 받아오고, 데이터 프레임이 비어있는 경우에는 100000000 값을 넣어주어 대체함. \n",
    "            a = np.array([len(df1) if len(df1) > 0 else 100000, len(df2) if len(df2) > 0 else 100000, len(df3) if len(df3) > 0 else 100000, len(df4) if len(df4) > 0 else 100000])\n",
    "            #length = a.min()\n",
    "            length = a.min()-1 # 최솟값에서 -1을 해줌. \n",
    "\n",
    "            # # def문을 활용해서 delta 값 만들기. \n",
    "            # def plus_minus(df):\n",
    "            #     df[\"box size\"] = df['box.width'] * df['box.height'] # 박스 사이즈 (얼굴 크기를 이야기 하는 것 )\n",
    " \n",
    "            #     W = \"box.width\"\n",
    "            #     H = \"box.height\"\n",
    "\n",
    "            #     df[\"box delta\"] = df[\"box size\"].diff() # 프레임 단위로 박스의 크기의 변화량을 체크\n",
    "            #     df_new = df.iloc[1:, 18] # ? 왜 열 값을 이렇게 주었을까? 첫 1번 열과 18개의 행만  \n",
    "                \n",
    "            #     for i in range(len(df_new)):\n",
    "            #         if(df_new.iloc[i] > 600):  # 평균적인 사이즈 값\n",
    "            #             df_new.iloc[i] = 1 # 앞으로 기울었을 때 \n",
    "            #         elif(df_new.iloc[i] < -600):\n",
    "            #             df_new.iloc[i] = -1 # 뒤로 기울었을 때 \n",
    "            #         else:\n",
    "            #             df_new.iloc[i] = 0 # 아무것도 아닐 때\n",
    "            #     return df_new \n",
    "   \n",
    "            # df1 = plus_minus(df1)\n",
    "            # print(df1)\n",
    "   \n",
    "   \n",
    "            if len(df1) > 0:\n",
    "                df1 = plus_minus(df1).iloc[:length] # if length > 0 else None\n",
    "            else: \n",
    "                df1 = pd.DataFrame({\"box delta_A1\": [0 for _ in range(length)]}) # {\"box delta\": [0 for _ in range(length)]}\n",
    "        \n",
    "            if len(df2) > 0:\n",
    "                df2 = plus_minus(df2).iloc[:length] \n",
    "            else:\n",
    "                df2 = pd.DataFrame({\"box delta_A2\": [0 for _ in range(length)]}) #{\"box delta\": [0 for _ in range(length)]}\n",
    "\n",
    "            if len(df3) > 0:\n",
    "                df3 = plus_minus(df3).iloc[:length]  \n",
    "            else:\n",
    "                df3 = pd.DataFrame({\"box delta_A3\": [0 for _ in range(length)]}) # {\"box delta\": [0 for _ in range(length)]}\n",
    "\n",
    "            if len(df4) > 0:\n",
    "                df4 = plus_minus(df4).iloc[:length]\n",
    "            else:\n",
    "                df4 = pd.DataFrame({\"box delta_A4\": [0 for _ in range(length)]}) # {\"box delta\": [0 for _ in range(length)]}\n",
    "            \n",
    "            # 각 그룹별 데이터가 저장되어 있는 데이터 프레임 값 저장. || axis = 1 (세로 (열) 형태로 저장될 수 있도록 함. ) \n",
    "            df_concat = pd.concat([df1,df2,df3,df4], axis = 1)\n",
    "            #print(df_concat.head())\n",
    "\n",
    "            df_concat['same'] = 0 \n",
    "                        \n",
    "            for i in range (len(df_concat)):\n",
    "                \n",
    "                count=df_concat.iloc[i].value_counts()\n",
    "                try:\n",
    "                    count[0] = 0\n",
    "                except:\n",
    "                    0\n",
    "            \n",
    "                df_concat.iloc[i,4] = count.max()\n",
    "            \n",
    "            same = np.array(df_concat[\"same\"])\n",
    "            #step_data.append((df_concat['same'] >= 3).sum())\n",
    "            \n",
    "            # 4명 모두 기울인 것.\n",
    "            step_data_4p.append(np.where(same>=4,1,0).sum())\n",
    "        \n",
    "        data.append([group, week] + step_data_4p)\n",
    "        # 새로운 데이터 프레임을 하나 만들어줄 것. \n",
    "        count_df = pd.DataFrame(data, columns=face_index)\n",
    "    \n",
    "         # out_folder 위치에 face_lean이 얼마나 기울어졌는지 기록하는 구간.  \n",
    "        count_df.to_excel(output_folder + \"Face_lean_count.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래의 경로로 변경\n",
    "os.chdir(\"D:/MultiModal/Face_z_score/Face_lean_count/\")\n",
    "all_df = pd.read_excel(\"C_Face_lean_count.xlsx\") \n",
    "\n",
    "#step_list = [\"S1_1\", \"S1_2\", \"S1_3\", \"S1_4\", \"S2_1\", \"S2_2\", \"S2_3\", \"S2_4\", \"S3\"]\n",
    "\n",
    "step_list = [\"S1\", \"S2\", \"S3\"]\n",
    "\n",
    "df_index = [\"Group\"] + [f\"{week}_{step}_Face_lean_3p\" for week in [\"1W\", \"2W\", \"3W\", \"4W\"] for step in step_list] \n",
    "### , \"2W\", \"3W\", \"4W\"\n",
    "data = []\n",
    "for group in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "    week_data = []\n",
    "    for week in [f\"{w_index}W\" for w_index in range(1, 5)]:\n",
    "        filtered_df = all_df[(all_df[\"Week\"] == week) & (all_df[\"Group\"] == group)]\n",
    "        week_data.extend(filtered_df[[f\"{step}_Face_lean_3p\" for step in step_list]].values.flatten().tolist())\n",
    "        print(filtered_df)\n",
    "    \n",
    "    data.append([group] + week_data)   \n",
    "\n",
    "all_summarize_df = pd.DataFrame(data, columns=df_index)\n",
    "all_summarize_df.to_excel(\"All_Face_lean_count(All group, excel_anaysis).xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 몸의 기울기 값 z_score 이상치 제거 코드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_outliers(df, column, z_score_threshold=3):\n",
    "    \n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "\n",
    "    z_scores = (df[column] - mean) / std\n",
    "    \n",
    "    outliers = abs(z_scores) > z_score_threshold\n",
    "\n",
    "    median_value = df[column].median()\n",
    "    df.loc[outliers, column] = median_value\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Body Scaling (이상치 처리) 정리 || 값을 조정해주는 코드\n",
    "\"\"\"\n",
    "import re\n",
    "import math\n",
    "\n",
    "for group in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "    os.chdir(f\"Users/nabi/Desktop/filtered_df/{group}/\")\n",
    "    \n",
    "    # 파일 불러오기\n",
    "    file_list = os.listdir(os.getcwd())\n",
    "    # 출력할 파일 불러오기\n",
    "    output_folder = f\"Users/nabi/Desktop/filtered_df_result/\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file in file_list:\n",
    "        if file.split('.')[-1] == \"xlsx\": # xlsx 파일만 읽기\n",
    "            body_df = pd.read_excel(file)\n",
    "\n",
    "            coordinate_columns = [col for col in body_df.columns if col.endswith(('.x', '.y', '.z'))]\n",
    "\n",
    "            for column in coordinate_columns:\n",
    "                filterd_df = correct_outliers(body_df, column)\n",
    "\n",
    "            filterd_df.iloc[:, 1:].to_excel(output_folder + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 몸의 기울기 값도 똑같이 얼굴 기울기를 셀 수 있도록 해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus_minus_1(df):\n",
    " \n",
    "    # body delta라는 이름의 데이터 프레임에 lambda로 조건식 주는 곳\n",
    "    #df[\"body delta\"] = df[\"body_lean\"].apply(lambda x: 1 if x < 90 else (-1 if x > 90 else 0))\n",
    "    \n",
    "    df[\"body delta\"] = df[\"Body_lean\"].diff()\n",
    "    #print(df[\"body delta\"])\n",
    "    \n",
    "    # 첫 번째 열은 비교할 수 있는 값이 없으므로, NaN값이 생길 수 있음. 이를 방지하기 위해 0 값을 할당. \n",
    "    df.loc[0, 'Body_lean'] = 0\n",
    "    df_new = df.iloc[1:, :][\"body delta\"] # 첫 번째 행은 제외, 제외하지 않을 경우, 비교할 값이 없어서 NaN값 생성. \n",
    "\n",
    "    # 절대값을 계산해서 비교.\n",
    "    #df_diff = abs(df_new)\n",
    "    \n",
    "    for i in range(len(df_new)):\n",
    "        \n",
    "        if(df_new.iloc[i] > 0.02):  # 평균적인 사이즈 값\n",
    "            df_new.iloc[i] = 1 # 앞으로 기울었을 때 \n",
    "        elif(df_new.iloc[i] < -0.02):\n",
    "            df_new.iloc[i] = -1 # 뒤로 기울었을 때 \n",
    "        elif(-0.02 < df_new.iloc[i] < 0.02):\n",
    "            df_new.iloc[i] = 0 # 아무것도 아닐 때\n",
    "    \n",
    "    return df_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 최종적으로 저장할 경로. \n",
    "data = []\n",
    "\n",
    "# 출력할 수 있는 경로 설정 \"D:/MultiModal/body_lean_all/body_lean_count/\"\n",
    "output_folder = f\"/Users/nabi/Desktop/body_lean_count/\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for group in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\"]: # f\"D:/MultiModal/body_lean_all/{group}/\"\n",
    "    os.chdir(f\"/Users/nabi/Desktop/filtered_mean_value/{group}/\")\n",
    "            \n",
    "    #스텝에 나와 있는 것 \n",
    "    step_list = [\"S1\", \"S2\", \"S3\"]\n",
    "    body_index = [\"Group\", \"Week\",] + [f\"{step}_Body_lean_3p\" for step in step_list]\n",
    "\n",
    "    for week in [f\"{w_index}W\" for w_index in range(1, 5)]:\n",
    "        step_data = []\n",
    "        for step in step_list: # lean_\n",
    "            df1 = pd.read_excel(f'Mean_filtered_{week}_{group}1_{step}.xlsx') if os.path.exists(f'Mean_filtered_{week}_{group}1_{step}.xlsx') else []\n",
    "            df2 = pd.read_excel(f'Mean_filtered_{week}_{group}2_{step}.xlsx') if os.path.exists(f'Mean_filtered_{week}_{group}2_{step}.xlsx') else []\n",
    "            df3 = pd.read_excel(f'Mean_filtered_{week}_{group}3_{step}.xlsx') if os.path.exists(f'Mean_filtered_{week}_{group}3_{step}.xlsx') else []\n",
    "            df4 = pd.read_excel(f'Mean_filtered_{week}_{group}4_{step}.xlsx') if os.path.exists(f'Mean_filtered_{week}_{group}4_{step}.xlsx') else []\n",
    "            \n",
    "            #print(df1)\n",
    "            #print(df2)\n",
    "            #print(df3)\n",
    "            #print(df4)\n",
    "            \n",
    "            #이상이 따로 없다면, df1~4까지의 len() 길이 값을 받아오고, 데이터 프레임이 비어있는 경우에는 100000000 값을 넣어주어 대체함. \n",
    "            a = np.array([len(df1) if len(df1) > 0 else 100000, len(df2) if len(df2) > 0 else 100000, len(df3) if len(df3) > 0 else 100000, len(df4) if len(df4) > 0 else 100000])\n",
    "            \n",
    "            length = a.min()-1 # 최솟값에서 -1을 해줌. \n",
    "\n",
    "            if len(df1) > 0:\n",
    "                df1 = plus_minus_1(df1).iloc[:length] # if length > 0 else None\n",
    "            else: \n",
    "                df1 = pd.DataFrame({\"body delta\": [0 for _ in range(length)]}) # {\"box delta\": [0 for _ in range(length)]}\n",
    "        \n",
    "            if len(df2) > 0:\n",
    "                df2 = plus_minus_1(df2).iloc[:length] \n",
    "            else:\n",
    "                df2 = pd.DataFrame({\"body delta\": [0 for _ in range(length)]}) #{\"box delta\": [0 for _ in range(length)]}\n",
    "\n",
    "            if len(df3) > 0:\n",
    "                df3 = plus_minus_1(df3).iloc[:length]  \n",
    "            else:\n",
    "                df3 = pd.DataFrame({\"body delta\": [0 for _ in range(length)]}) # {\"box delta\": [0 for _ in range(length)]}\n",
    "\n",
    "            if len(df4) > 0:\n",
    "                df4 = plus_minus_1(df4).iloc[:length]\n",
    "            else:\n",
    "                df4 = pd.DataFrame({\"body delta\": [0 for _ in range(length)]}) # {\"box delta\": [0 for _ in range(length)]}\n",
    "        \n",
    "            # 각 그룹별 데이터가 저장되어 있는 데이터 프레임 값 저장. || axis = å1 (세로 (열) 형태로 저장될 수 있도록 함. ) \n",
    "            df_concat = pd.concat([df1,df2,df3,df4], axis = 1)\n",
    "            #print(df_concat.head())\n",
    "\n",
    "            # same 열 초기화 \n",
    "            df_concat['same'] = 0 \n",
    "                        \n",
    "            for i in range (len(df_concat)):\n",
    "                #print(i)\n",
    "                # df_concat.iloc[] 번째의 값을 카운트\n",
    "                count=df_concat.iloc[i].value_counts()\n",
    "                try:\n",
    "                    count[0] = 0\n",
    "                except:\n",
    "                    0\n",
    "            \n",
    "                df_concat.iloc[i,4] = count.max()\n",
    "            \n",
    "            same = np.array(df_concat[\"same\"])  \n",
    "            # step_data 리스트 안에는 same 값이 3보다 크다면 인덱스 값을 반환해서, 만족하면 1 아니면 0을 반환. \n",
    "            step_data.append(np.where(same>=3,1,0).sum())\n",
    "    \n",
    "        data.append([group, week] + step_data)\n",
    "        # # 새로운 데이터 프레임을 하나 만들어줄 것. \n",
    "        count_df = pd.DataFrame(data, columns=body_index)\n",
    "    \n",
    "        # out_folder 위치에 face_lean이 얼마나 기울어졌는지 기록하는 구간.  \n",
    "        count_df.to_excel(output_folder + \"All_Body_lean_count.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래의 경로로 변경\n",
    "os.chdir(\"/Users/nabi/Desktop/body_lean_count/\") # \"D:/MultiModal/body_lean_all/body_lean_count/\"\n",
    "all_df = pd.read_excel(\"All_Body_lean_count.xlsx\") \n",
    "\n",
    "#step_list = [\"S1_1\", \"S1_2\", \"S1_3\", \"S1_4\", \"S2_1\", \"S2_2\", \"S2_3\", \"S2_4\", \"S3\"]\n",
    "\n",
    "step_list = [\"S1\", \"S2\", \"S3\"]\n",
    "\n",
    "df_index = [\"Group\"] + [f\"{week}_{step}_Body_lean_3p\" for week in [\"1W\", \"2W\", \"3W\", \"4W\"] for step in step_list] \n",
    "### , \"2W\", \"3W\", \"4W\"\n",
    "data = []\n",
    "for group in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "    week_data = []\n",
    "    for week in [f\"{w_index}W\" for w_index in range(1, 5)]:\n",
    "        filtered_df = all_df[(all_df[\"Week\"] == week) & (all_df[\"Group\"] == group)]\n",
    "        week_data.extend(filtered_df[[f\"{step}_Body_lean_3p\" for step in step_list]].values.flatten().tolist())\n",
    "    \n",
    "    data.append([group] + week_data)   \n",
    "\n",
    "all_summarize_df = pd.DataFrame(data, columns=df_index)\n",
    "all_summarize_df.to_excel(\"All_Body_lean_count(All group, excel_anaysis).xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## body_lean의 diff() 값을 계산해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_the_diff(df):\n",
    "    # body_diff 라는 이름의 열 하나 생성. || 그리고 body_lean에 대한 diff() * 열 간의 차이 값 계산. \n",
    "    df['body diff'] = df['Body_lean'].diff()\n",
    "    \n",
    "    # 첫 번째 열은 비교할 수 있는 값이 없으므로, NaN값이 생길 수 있음. 이를 방지하기 위해 0 값을 할당. \n",
    "    df.loc[0, 'Body_lean'] = 0\n",
    "        \n",
    "    # diff_df 라는 변수 안에 body diff 전체 값을 넣어 줌. \n",
    "    diff_df = df.iloc[1:, :][\"body diff\"]\n",
    "    \n",
    "    result_df = np.median(diff_df)\n",
    "    result = abs(result_df)\n",
    "\n",
    "    # 마지막 result에는 diff() 값을 반환. \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# 최종적으로 저장할 경로. \n",
    "data = []\n",
    "\n",
    "for group in [\"B\"]: \n",
    "    os.chdir(f\"/Users/nabi/Desktop/filtered_mean_value/{group}/\")\n",
    "\n",
    "    read_dir = pd.read_excel(\"Mean_filtered_4W_B1_S1.xlsx\")\n",
    "    result_diff = show_the_diff(read_dir)\n",
    "    \n",
    "    print(result_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱스 정보 값을 넣어주기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "body_path = r\"D:\\\\MultiModal\\\\body_lean_all\\\\G\\\\\"\n",
    " \n",
    "outpath = r\"D:\\\\MultiModal\\\\body_lean_all\\\\body_lean_count\\\\lean(4p_2)\\\\G\\\\\"\n",
    " \n",
    " \n",
    "# 파일 리스트 값을 불러오기. \n",
    "list = os.listdir(body_path)\n",
    "\n",
    "# 리스트 내에 있는 파일 하나씩 읽어오기. \n",
    "for file in list:\n",
    "    read_file = os.path.join(body_path, file)\n",
    "    read_f = pd.read_excel(read_file)\n",
    "    \n",
    "    index_val = []\n",
    "    \n",
    "    for i in read_f.index:\n",
    "        index_val.append(i)\n",
    "        \n",
    "    new_df = pd.DataFrame(columns= [\"Frame\"])\n",
    "    new_df[\"Frame\"] = index_val\n",
    "    \n",
    "    result = pd.concat([new_df, read_f], axis= 1, ignore_index=False)\n",
    "    result.style.hide(axis='index')\n",
    "    \n",
    "    result.to_excel(outpath + f\"Add_{file}\", index=False)\n",
    "    #print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4명 중에 N명 기울어진 정도 + Frame 시간에 맞게 뽑아낸 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 크기 변화량 값 계산하는 구간. \n",
    "def plus_minus(df):\n",
    "    df[\"box size\"] = df['box.width'] * df['box.height'] # 박스 사이즈 (얼굴 크기를 이야기 하는 것 )\n",
    "\n",
    "    W = \"box.width\"\n",
    "    H = \"box.height\"\n",
    "\n",
    "    df[\"box delta\"] = df[\"box size\"].diff() # 프레임 단위로 박스의 크기의 변화량을 체크\n",
    "    df_new = df.iloc[1:, :][\"box delta\"] # 첫 번째 행은 제외, 제외하지 않을 경우, 비교할 값이 없어서 NaN값 생성. \n",
    "    # df_new 값일 어떻게 생성되는지 확인해보기 위해 출력. \n",
    "    #print(df_new)\n",
    "    \n",
    "    for i in range(len(df_new)):\n",
    "        \n",
    "        if(df_new.iloc[i] > 250):  # 평균적인 사이즈 값\n",
    "            df_new.iloc[i] = 1 # 앞으로 기울었을 때 \n",
    "        elif(df_new.iloc[i] < -250):\n",
    "            df_new.iloc[i] = -1 # 뒤로 기울었을 때 \n",
    "        else:\n",
    "            df_new.iloc[i] = 0 # 아무것도 아닐 때\n",
    "    return df_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 최종적으로 저장할 경로. \n",
    "data = []\n",
    "\n",
    "# 5분 단위로 자른 것이 아닐 때의 값을 저장하기 위한 부분. \n",
    "# output_folder = f\"D:/MultiModal/Face_z_score/Face_lean_count/backup/box_delta_not_5m/\"\n",
    "\n",
    "output_folder = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\05_27_box_delta_zip\\\\C_250\\\\\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# D:\\MultiModal\\Face_z_score\\Face_lean_count\\backup\\All_face_box_zip\\box_delta_not_5min\n",
    "\n",
    "for group in [\"C\"]: # \"A\",\"B\",\"C\", \"D\", \"E\", \"F\", \"G\"\n",
    "    os.chdir(f\"D:/MultiModal/Face_z_score/{group}/\") \n",
    "    \n",
    "    # 5분 단위로 잘라 놓은 부분들의 diff() 값들을 구해 놓은 부분. \n",
    "    #os.chdir(f\"D:/MultiModal/Face_z_score/face_landmark_Split/{group}/\") \n",
    "    step_list = [\"S1\", \"S2\", \"S3\"]\n",
    "    #step_list = [\"S1_1\", \"S1_2\", \"S1_3\",\"S1_4\", \"S2_1\", \"S2_2\", \"S2_3\", \"S2_4\", \"S3\"]\n",
    "\n",
    "    # 3명이 기울었을 때, 2명이 기울었을 때, 1명이 기울었을 때.\n",
    "    #face_index = [\"Group\", \"Week\",] + [f\"{step}_Face_lean_3p\" for step in step_list] + [f\"{step}_Face_lean_2p\" for step in step_list] + [f\"{step}_Face_lean_1p\" for step in step_list]\n",
    "    face_index = [f\"{step}_Face_lean_3p\" for step in step_list] + [f\"{step}_Face_lean_2p\" for step in step_list] + [f\"{step}_Face_lean_1p\" for step in step_list]\n",
    "\n",
    "    for week in [f\"{w_index}W\" for w_index in range(1, 5)]:\n",
    "        # step 3개.\n",
    "        for step in step_list:\n",
    "            df1 = pd.read_excel(f'Face_{week}_{group}1_{step}.xlsx') if os.path.exists(f'Face_{week}_{group}1_{step}.xlsx') else []\n",
    "            df2 = pd.read_excel(f'Face_{week}_{group}2_{step}.xlsx') if os.path.exists(f'Face_{week}_{group}2_{step}.xlsx') else []\n",
    "            df3 = pd.read_excel(f'Face_{week}_{group}3_{step}.xlsx') if os.path.exists(f'Face_{week}_{group}3_{step}.xlsx') else []\n",
    "            df4 = pd.read_excel(f'Face_{week}_{group}4_{step}.xlsx') if os.path.exists(f'Face_{week}_{group}4_{step}.xlsx') else []\n",
    "            \n",
    "            #이상이 따로 없다면, df1~4까지의 len() 길이 값을 받아오고, 데이터 프레임이 비어있는 경우에는 100000 값을 넣어주어 대체함. \n",
    "            a = np.array([len(df1) if len(df1) > 0 else 100000, len(df2) if len(df2) > 0 else 100000, len(df3) if len(df3) > 0 else 100000, len(df4) if len(df4) > 0 else 100000])\n",
    "        \n",
    "            length = a.min()-1 # 최솟값에서 -1을 해줌. \n",
    "            \n",
    "            if len(df1) > 0:\n",
    "                df1 = plus_minus(df1).iloc[:length] # if length > 0 else None\n",
    "            else: \n",
    "                df1 = pd.DataFrame({\"box delta_C1\": [0 for _ in range(length)]}) # {\"box delta\": [0 for _ in range(length)]}\n",
    "        \n",
    "            if len(df2) > 0:\n",
    "                df2 = plus_minus(df2).iloc[:length] \n",
    "            else:\n",
    "                df2 = pd.DataFrame({\"box delta_C2\": [0 for _ in range(length)]}) #{\"box delta\": [0 for _ in range(length)]}\n",
    "\n",
    "            if len(df3) > 0:\n",
    "                df3 = plus_minus(df3).iloc[:length]  \n",
    "            else:\n",
    "                df3 = pd.DataFrame({\"box delta_C3\": [0 for _ in range(length)]}) # {\"box delta\": [0 for _ in range(length)]}\n",
    "\n",
    "            if len(df4) > 0:\n",
    "                df4 = plus_minus(df4).iloc[:length]\n",
    "            else:\n",
    "                df4 = pd.DataFrame({\"box delta_C4\": [0 for _ in range(length)]}) # {\"box delta\": [0 for _ in range(length)]}\n",
    "            \n",
    "            # 각 그룹별 데이터가 저장되어 있는 데이터 프레임 값 저장. || axis = 1 (세로 (열) 형태로 저장될 수 있도록 함. ) \n",
    "            df_concat = pd.concat([df1,df2,df3,df4], axis = 1)\n",
    "            \n",
    "            df_concat.to_excel(output_folder + f\"box_delta_diff_{week}_{group}_{step}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## box_delta 1~4 중 각 조건에 맞게 12프레임 중 8개가 -1 이라면 -1로 쭉 기록 || 1이라면 1로 쭉 기록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1 혹은 1이 10개 이상 되는 행을 찾아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_consecutive_values(series, value, min_count):\n",
    "    count = 0\n",
    "    start_index = -1\n",
    "    ranges = []\n",
    "    \n",
    "    for i, v in enumerate(series):\n",
    "        if v == value:\n",
    "            if count == 0:\n",
    "                start_index = i\n",
    "            count += 1\n",
    "        else:\n",
    "            if count >= min_count:\n",
    "                ranges.append((start_index, i - 1))\n",
    "            count = 0\n",
    "    \n",
    "    if count >= min_count:\n",
    "        ranges.append((start_index, len(series) - 1))\n",
    "    \n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 행부터 50행(=25 프레임)까지, 1 혹은 -1의 값이 얼마나 있을까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_count(df, window_size, value_list, min_count):\n",
    "    n = len(df)\n",
    "    for start in range(n - window_size + 1):\n",
    "        end = start + window_size\n",
    "        subset_df = df.iloc[start:end]\n",
    "        count = subset_df['box delta.2'].isin(value_list).sum()\n",
    "        if count >= min_count:\n",
    "            return start, end - 1, count\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1이 0~50행 내에서 20개 이상 있는지 확인하기 위한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_count_ones(df, window_size, target_value, min_count): # window_size => 50개의 행만큼 건너뛰어서 보고 싶은 것. \n",
    "    # target_value = 1(or 1) # min_count = 20개(* 80%)\n",
    "    n = len(df)\n",
    "    list1 = []\n",
    "    for start in range(0, n, window_size): # window_size 만큼 건너뛰면서 확인. \n",
    "        end = start + window_size\n",
    "        subset_df = df.iloc[start:end]\n",
    "        count = (subset_df['box delta.1'] == target_value).sum() # lean_3p\n",
    "        # count >=12 이라면, 갯수가 몇 개인 지를 카운트 해주는 부분\n",
    "        if count >= min_count:\n",
    "            list1.append((start, end - 1, count))     \n",
    "            \n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_count_ones(df, window_size, target_value, min_count):\n",
    "    n = len(df)\n",
    "    columns_to_check = ['box delta', 'box delta.1', 'box delta.2', 'box delta.3']\n",
    "    \n",
    "    for start in range(0, n, window_size):\n",
    "        end = min(start + window_size, n)  # Ensure we do not go out of bounds\n",
    "        subset_df = df.iloc[start:end]\n",
    "        \n",
    "        # Check if any of the columns in the current window meet the condition\n",
    "        for column in columns_to_check:\n",
    "            count = (subset_df[column] == target_value).sum()\n",
    "            if count >= min_count:\n",
    "                df.iloc[start:end, df.columns.get_indexer(columns_to_check)] = target_value\n",
    "                break  # Once one column meets the condition, we update the entire window and move on\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## box.delta 값이 연속으로 1인 값이 7개 이상일 때의 열을 찾는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:/MultiModal/Face_z_score/Face_lean_count/backup/All_face_box_zip/05_27_box_delta_zip/C_250/\"\n",
    "# D:\\MultiModal\\Face_z_score\\Face_lean_count\\backup\\All_face_box_zip\\05_27_box_delta_zip\\C_250\n",
    "#print(os.getcwd())\n",
    "\n",
    "os.chdir(path)\n",
    "#print(os.getcwd())\n",
    "for week in [\"1W\", \"2W\", \"3W\", \"4W\"]:\n",
    "    for step in [\"S1\", \"S2\", \"S3\"]:\n",
    "        read_data = pd.read_excel(f\"box_delta_diff_{week}_C_{step}.xlsx\", index_col=0)\n",
    "        \n",
    "        # -1 값이 7개 이상으로 나오는 곳 \n",
    "        consecutive_ranges = find_consecutive_values(read_data['box delta.1'], 1, 7)\n",
    "        for start, end in consecutive_ranges:\n",
    "            print(f\"연속된 1 값이 {week}_C_{step}파일에서, {start}에서 {end}까지 발견됨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0~50행까지 계속 탐색해보았을 떄, 1이 연속으로 20개 이상 있는 곳을 찾는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_count_values(df, window_size, target_value_1, target_value_2, min_count):\n",
    "    n = len(df)\n",
    "    columns_to_check = ['box delta', 'box delta.1', 'box delta.2', 'box delta.3']\n",
    "    \n",
    "    for start in range(0, n, window_size):\n",
    "        end = min(start + window_size, n)  # Ensure we do not go out of bounds\n",
    "        subset_df = df.iloc[start:end]\n",
    "        \n",
    "        # Check counts for both target values\n",
    "        count_1 = (subset_df[columns_to_check] == target_value_1).sum().sum()\n",
    "        count_minus_1 = (subset_df[columns_to_check] == target_value_2).sum().sum()\n",
    "        \n",
    "        if count_1 >= min_count:\n",
    "            df.iloc[start:end, df.columns.get_indexer(columns_to_check)] = target_value_1\n",
    "        elif count_minus_1 >= min_count:\n",
    "            df.iloc[start:end, df.columns.get_indexer(columns_to_check)] = target_value_2\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1W_C_S1파일에서, 행 2292에서 2303까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 2460에서 2471까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 3624에서 3635까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 6540에서 6551까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 8232에서 8243까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "1W_C_S1파일에서, 행 10104에서 10115까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 11664에서 11675까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "1W_C_S1파일에서, 행 14724에서 14735까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 14748에서 14759까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "1W_C_S1파일에서, 행 14760에서 14771까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 16236에서 16247까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "1W_C_S1파일에서, 행 16356에서 16367까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 26496에서 26507까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 27540에서 27551까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S1파일에서, 행 29496에서 29507까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 2880에서 2891까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 4080에서 4091까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 4164에서 4175까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "1W_C_S2파일에서, 행 5520에서 5531까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 6312에서 6323까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 6396에서 6407까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 7668에서 7679까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 8172에서 8183까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "1W_C_S2파일에서, 행 9984에서 9995까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 10392에서 10403까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 11292에서 11303까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 20340에서 20351까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 21516에서 21527까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "1W_C_S2파일에서, 행 23172에서 23183까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 23640에서 23651까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 25176에서 25187까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 25512에서 25523까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 26388에서 26399까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 26748에서 26759까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S2파일에서, 행 27300에서 27311까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "1W_C_S3파일에서, 행 2364에서 2375까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "1W_C_S3파일에서, 행 4260에서 4271까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 1728에서 1739까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 2400에서 2411까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "2W_C_S1파일에서, 행 2796에서 2807까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "2W_C_S1파일에서, 행 4836에서 4847까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 5436에서 5447까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 7260에서 7271까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 11616에서 11627까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 13800에서 13811까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "2W_C_S1파일에서, 행 15672에서 15683까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 16944에서 16955까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 17796에서 17807까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 17880에서 17891까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 18780에서 18791까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 18960에서 18971까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 22104에서 22115까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 23640에서 23651까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 25956에서 25967까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S1파일에서, 행 26916에서 26927까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 3144에서 3155까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 3912에서 3923까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 7860에서 7871까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 8544에서 8555까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 11160에서 11171까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 11448에서 11459까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 19296에서 19307까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 19620에서 19631까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 20964에서 20975까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 22392에서 22403까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 22560에서 22571까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 25284에서 25295까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 25644에서 25655까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S2파일에서, 행 26316에서 26327까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S3파일에서, 행 336에서 347까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S3파일에서, 행 492에서 503까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "2W_C_S3파일에서, 행 600에서 611까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S3파일에서, 행 1380에서 1391까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S3파일에서, 행 3156에서 3167까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "2W_C_S3파일에서, 행 4716에서 4727까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 168에서 179까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "3W_C_S1파일에서, 행 1704에서 1715까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 6972에서 6983까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 7128에서 7139까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 7416에서 7427까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 9108에서 9119까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 9276에서 9287까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "3W_C_S1파일에서, 행 9420에서 9431까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 11424에서 11435까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 13836에서 13847까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 16176에서 16187까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 16296에서 16307까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 16416에서 16427까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 16452에서 16463까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 17880에서 17891까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 20160에서 20171까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 21408에서 21419까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 21660에서 21671까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 21948에서 21959까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 22104에서 22115까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 22116에서 22127까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 23376에서 23387까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 26448에서 26459까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S1파일에서, 행 26796에서 26807까지의 구간에서 값이 1인 개수는 10입니다.\n",
      "3W_C_S2파일에서, 행 120에서 131까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 324에서 335까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 396에서 407까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 720에서 731까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 2880에서 2891까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 5484에서 5495까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "3W_C_S2파일에서, 행 8532에서 8543까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 8700에서 8711까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 10704에서 10715까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 11064에서 11075까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 11460에서 11471까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 11724에서 11735까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 11784에서 11795까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 15720에서 15731까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 16644에서 16655까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 17772에서 17783까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "3W_C_S2파일에서, 행 18180에서 18191까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 18288에서 18299까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 23628에서 23639까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 24156에서 24167까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 24720에서 24731까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 25524에서 25535까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 26844에서 26855까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 28416에서 28427까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 28680에서 28691까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S2파일에서, 행 28764에서 28775까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "3W_C_S2파일에서, 행 29208에서 29219까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S3파일에서, 행 972에서 983까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "3W_C_S3파일에서, 행 2580에서 2591까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S3파일에서, 행 3480에서 3491까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S3파일에서, 행 3852에서 3863까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S3파일에서, 행 4488에서 4499까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S3파일에서, 행 5208에서 5219까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "3W_C_S3파일에서, 행 5676에서 5687까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 264에서 275까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 1008에서 1019까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 1332에서 1343까지의 구간에서 값이 1인 개수는 10입니다.\n",
      "4W_C_S1파일에서, 행 2208에서 2219까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 2556에서 2567까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 2760에서 2771까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 3552에서 3563까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 3996에서 4007까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 5496에서 5507까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 6084에서 6095까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 6564에서 6575까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 9084에서 9095까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 10932에서 10943까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 11688에서 11699까지의 구간에서 값이 1인 개수는 10입니다.\n",
      "4W_C_S1파일에서, 행 13740에서 13751까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 15144에서 15155까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "4W_C_S1파일에서, 행 17220에서 17231까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 18588에서 18599까지의 구간에서 값이 1인 개수는 10입니다.\n",
      "4W_C_S1파일에서, 행 20928에서 20939까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "4W_C_S1파일에서, 행 21576에서 21587까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 21768에서 21779까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 24852에서 24863까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "4W_C_S1파일에서, 행 25752에서 25763까지의 구간에서 값이 1인 개수는 10입니다.\n",
      "4W_C_S1파일에서, 행 25896에서 25907까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S1파일에서, 행 28116에서 28127까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "4W_C_S1파일에서, 행 28272에서 28283까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 132에서 143까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 1500에서 1511까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 1596에서 1607까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 2460에서 2471까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "4W_C_S2파일에서, 행 3300에서 3311까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 4260에서 4271까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 6660에서 6671까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 8028에서 8039까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 9768에서 9779까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 9852에서 9863까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 10884에서 10895까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 12408에서 12419까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 12420에서 12431까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 13344에서 13355까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 13464에서 13475까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 13512에서 13523까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 14736에서 14747까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 14748에서 14759까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 15516에서 15527까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 16188에서 16199까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 16248에서 16259까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 21252에서 21263까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 21336에서 21347까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 22200에서 22211까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 22536에서 22547까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 25464에서 25475까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 25848에서 25859까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 27828에서 27839까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S2파일에서, 행 28992에서 29003까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S3파일에서, 행 3720에서 3731까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S3파일에서, 행 4668에서 4679까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "4W_C_S3파일에서, 행 4992에서 5003까지의 구간에서 값이 1인 개수는 9입니다.\n",
      "4W_C_S3파일에서, 행 6372에서 6383까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S3파일에서, 행 6636에서 6647까지의 구간에서 값이 1인 개수는 8입니다.\n",
      "4W_C_S3파일에서, 행 6984에서 6995까지의 구간에서 값이 1인 개수는 8입니다.\n"
     ]
    }
   ],
   "source": [
    "#path = r\"D:/MultiModal/Face_z_score/Face_lean_count/backup/All_face_box_zip/05_27_box_delta_zip/C_250/\"\n",
    "# D:\\MultiModal\\Face_z_score\\Face_lean_count\\backup\\All_face_box_zip\\05_27_box_delta_zip\\C_250\n",
    "input = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\Check\\\\\"\n",
    "#print(os.getcwd())\n",
    "\n",
    "os.chdir(input)\n",
    "#print(os.getcwd())\n",
    "for week in [\"1W\", \"2W\", \"3W\", \"4W\"]:\n",
    "    for step in [\"S1\", \"S2\", \"S3\"]:\n",
    "        read_data = pd.read_excel(f\"box_delta_{week}_C_{step}.xlsx\", index_col=0)\n",
    "        \n",
    "        # 첫 50행씩 이동하며 1 또는 -1의 개수를 확인\n",
    "        #result = sliding_window_count(read_data, 50, [-1, 1], 20)\n",
    "        result = sliding_window_count_ones(read_data, 12, -1, 8)    \n",
    "        # 결과 출력\n",
    "        if result:\n",
    "            for start, end, count in result:\n",
    "                print(f\"{week}_C_{step}파일에서, 행 {start}에서 {end}까지의 구간에서 값이 1인 개수는 {count}입니다.\")\n",
    "        else:\n",
    "            print(\"조건을 만족하는 구간이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified_box_delta_1W_C_S1.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_1W_C_S2.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_1W_C_S3.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_2W_C_S1.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_2W_C_S2.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_2W_C_S3.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_3W_C_S1.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_3W_C_S2.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_3W_C_S3.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_4W_C_S1.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_4W_C_S2.xlsx 파일이 저장되었습니다.\n",
      "modified_box_delta_4W_C_S3.xlsx 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "path = r\"D:/MultiModal/Face_z_score/Face_lean_count/backup/All_face_box_zip/05_27_box_delta_zip/C_250/\"\n",
    "if not os.path.exists(path):os.makedirs(path)\n",
    "# input = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\Check\\\\\"\n",
    "#print(os.getcwd())\n",
    "\n",
    "os.chdir(path)\n",
    "#print(os.getcwd())\n",
    "for week in [\"1W\", \"2W\", \"3W\", \"4W\"]:\n",
    "    for step in [\"S1\", \"S2\", \"S3\"]:\n",
    "        read_data = pd.read_excel(f\"box_delta_diff_{week}_C_{step}.xlsx\", index_col=0)\n",
    "        # box_delta_diff_1W_C_S1\n",
    "        \n",
    "        # 첫번째부터 12행씩 이동하며 1 또는 -1의 개수를 확인\n",
    "        result = sliding_window_count_values(read_data, 12, 1, -1, 8)    \n",
    "        # 결과 출력\n",
    "        result_path = f\"modified_box_delta_{week}_C_{step}.xlsx\"\n",
    "        result.to_excel(result_path)\n",
    "        print(f\"{result_path} 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box delta 간의 diff() 값을 구했으니, 이에 맞게 몇 명이 기울었는지를 체크하는 구간."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "\n",
    "### 5분 단위로 자르지 않은 부분들을 모아놓은 곳. \n",
    "#out_folder = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\05_27_box_delta_zip\\\\Output_C\\\\\"\n",
    "Out_folder = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\Check_C250\\\\\"\n",
    "if not os.path.exists(Out_folder):\n",
    "    os.makedirs(Out_folder)\n",
    "\n",
    "#input = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\05_27_box_delta_zip\\\\C\\\\\"\n",
    "#input = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\box_delta_not_5min\\\\\"\n",
    "path = r\"D:/MultiModal/Face_z_score/Face_lean_count/backup/All_face_box_zip/05_27_box_delta_zip/C_250/\"\n",
    "\n",
    "\n",
    "for group in [\"C\"]: # \"C\"\n",
    "    for week in [\"1W\",\"2W\",\"3W\",\"4W\"]:\n",
    "        for step in [\"S1\", \"S2\", \"S3\"]: # , \"S2\", \"S3\"\n",
    "            # \"S1_1\", \"S1_2\", \"S1_3\",\"S1_4\", \"S2_1\", \"S2_2\", \"S2_3\", \"S2_4\", \"S3\"\n",
    "            os.chdir(path)\n",
    "            read_file = pd.read_excel(f\"modified_box_delta_{week}_{group}_{step}.xlsx\")\n",
    "            #print(len(read_file))\n",
    "            \n",
    "            step_data_3p = []\n",
    "            step_data_2p = []\n",
    "            step_data_1p = []\n",
    "            \n",
    "            # 동시에 기울어진 사람들을 카운트 하는 구간. \n",
    "            read_file['same']=0 \n",
    "                    \n",
    "            for i in range (len(read_file)):\n",
    "                #print(read_file.iloc[i, 1:5])\n",
    "                val_count = read_file.iloc[i,1:5].value_counts()\n",
    "                # val_count 안에 있는 값이 0 이라면 0으로 초기화. \n",
    "                val_count[0] = 0\n",
    "                # 최댓값을 넣어주려는 부분. \n",
    "                #print(read_file.iloc[i, :5])\n",
    "                read_file.iloc[i,5] = val_count.max()\n",
    "                \n",
    "            same = np.array(read_file[\"same\"])\n",
    "\n",
    "            # 동시에 4명 중 N명이 기울었을 때를 세는 부분 || 모두 list 안에 들어있는 것. \n",
    "            step_data_3p = np.where(same>=3,1,0)\n",
    "            step_data_2p = np.where(same>=2,1,0)\n",
    "            step_data_1p = np.where(same>=1,1,0)\n",
    "        \n",
    "            # lean_4p, 3p,2p,1p에 맞게 데이터 값을 데이터 프레임으로 지정. \n",
    "            lean_3p = pd.DataFrame({\"lean_3p\" : step_data_3p})\n",
    "            lean_2p = pd.DataFrame({\"lean_2p\" : step_data_2p})\n",
    "            lean_1p = pd.DataFrame({\"lean_1p\" : step_data_1p})    \n",
    "            \n",
    "            # 데이터 프레임 합치는 구간. \n",
    "            new_df = pd.concat([read_file, lean_3p], axis=1)\n",
    "            new_df_1 = pd.concat([new_df, lean_2p], axis=1)\n",
    "            new_df_2 = pd.concat([new_df_1, lean_1p], axis=1)\n",
    "            \n",
    "            # Unnamed 0 열 지우기.\n",
    "            #new_df_2.drop(['Unnamed 0'], axis= 1, inplace=True)\n",
    "            \n",
    "            # 엑셀 파일 값으로 저장하는 부분.\n",
    "            os.chdir(Out_folder) \n",
    "            new_df_2.to_excel(f\"Box_delta_{week}_{group}_{step}.xlsx\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same열이 있다면, 보이지 않도록 지우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "## All_face_lean_5m => 5분 단위로 자른 것을 넣는 부분. \n",
    "out_path = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\Add_Lean_3p_C\\\\\"\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "for group in [\"C\"]:\n",
    "    for week in [\"1W\",\"2W\",\"3W\",\"4W\"]:\n",
    "        # 5분 단위로 나누어서 필요없는 데이터 지우기. \n",
    "        for step in [\"S1\", \"S2\", \"S3\"]:\n",
    "            # \"S1_1\", \"S1_2\", \"S1_3\",\"S1_4\", \"S2_1\", \"S2_2\", \"S2_3\", \"S2_4\", \"S3\"\n",
    "            os.chdir(r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\Check_C250\\\\\")\n",
    "            # D:/MultiModal/Face_z_score/Face_lean_count/backup/All_face_box_zip/box_delta_not_5min/\n",
    "            # D:/MultiModal/Face_z_score/Face_lean_count/backup/All_face_box_zip/box_delta_5m/\n",
    "            # r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\05_27_box_delta_zip\\\\Output_A\\\\\"\n",
    "            \n",
    "            # New Analysis data file dir\n",
    "            #r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\Check_C250\\\\\"\n",
    "            \n",
    "            \n",
    "            read_file = pd.read_excel(f\"Box_delta_{week}_{group}_{step}.xlsx\", index_col=0)\n",
    "\n",
    "            # Unnamed: 0 이라는 이름을 가진 column 지우기. \n",
    "            # if 'Unnamed: 0' in read_file.columns:\n",
    "            #      read_file.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "            # same 열 지우기.\n",
    "            if 'same' in read_file.columns:\n",
    "                read_file.drop(['same'], axis=1, inplace=True)\n",
    "                \n",
    "            read_file.rename(columns = {\n",
    "                \"box delta\": \"box_delta_C1\",\n",
    "                \"box delta.1\": \"box_delta_C2\",\n",
    "                \"box delta.2\": \"box_delta_C3\",\n",
    "                \"box delta.3\": \"box_delta_C4\"}, inplace=True)    \n",
    "                            \n",
    "            read_file.to_excel(out_path + f\"Box_delta_{week}_{group}_{step}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20분을 5분씩 4개의 파일로 끊어서 저장해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "for group in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\"]: # D:\\MultiModal\\Face_z_score\n",
    "    os.chdir(f\"D:\\\\MultiModal\\\\Face_z_score\\\\{group}\\\\\")\n",
    "    \n",
    "    # 파일 불러오기\n",
    "    file_list = os.listdir(os.getcwd())\n",
    "    \n",
    "    # 출력할 파일 불러오기\n",
    "    output_folder = f\"D:\\\\MultiModal\\\\Face_z_score\\\\face_landmark_Split\\\\{group}\\\\\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file in file_list:\n",
    "        if file.split('.')[-1] == \"xlsx\": \n",
    "            data_df = pd.read_excel(file)\n",
    "            data_index = data_df.iloc[:, 1:].columns.to_list()\n",
    "\n",
    "            file_name = file.split('.')[0]\n",
    "            #print(file_name.split('_')[4])\n",
    "\n",
    "            if file_name.split('_')[4] == \"S3\" or file_name.split('_')[4] == \"Baseline\":\n",
    "                data_df.iloc[:, 1:].to_excel(output_folder + file_name + '.xlsx')\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                num_splits = 4\n",
    "                \n",
    "                rows_per_split = len(data_df) // num_splits\n",
    "\n",
    "                for i in range(num_splits):\n",
    "                    # 마지막 부분 처리\n",
    "                    if i == num_splits - 1:\n",
    "                        split_df = data_df[i * rows_per_split:]\n",
    "                    else:\n",
    "                        split_df = data_df[i * rows_per_split:(i + 1) * rows_per_split]\n",
    "                        \n",
    "                    split_df.iloc[:, 1:].to_excel(output_folder + f'{file_name}_{i + 1}.xlsx', index=data_index)\n",
    "\n",
    "                print(f'{num_splits}개의 파일로 나누기 완료.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lean_1p에 대한 값의 합을 구해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 합산 값을 보기 위한 output 경로 \n",
    "output = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\Not_5m_lean_1p\\\\\"\n",
    "\n",
    "data = []\n",
    "\n",
    "for group in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "    for week in [\"1W\", \"2W\", \"3W\", \"4W\"]:\n",
    "        for step in [\"S1_1\",\"S1_2\",\"S1_3\",\"S1_4\",\"S2_1\",\"S2_2\",\"S2_3\",\"S2_4\",\"S3\"]:\n",
    "            # 현재 디렉토리로 변경 \n",
    "            os.chdir(r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\All_face_lean_5m\\\\\") \n",
    "            read_data = pd.read_excel(f\"box_delta_{week}_{group}_{step}.xlsx\", index_col=0)\n",
    "        \n",
    "            result = read_data[\"lean_1p\"].sum()\n",
    "            \n",
    "            data.append(result)\n",
    "            print(data)\n",
    "\n",
    "temp_df = pd.DataFrame(data, columns=[\"SUM_LEAN_1P\"])\n",
    "temp_df.to_excel(output + \"LEAN_1P_SUM.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lean 4p 열을 추가해보자 (same = Lean 4p) 값이랑 똑같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# 파일을 읽기 위한 경로\n",
    "# read_file = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\Modify_time\\\\Modify_time_5m\"\n",
    "\n",
    "# lean_4p를 추가하기 위해 필요한 output 경로\n",
    "output = \"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\05_27_box_delta_zip\\\\Add_Lean_4p_C\\\\\"\n",
    "# D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\Modify_box_size_all\\\\Modify_time_5m\n",
    "\n",
    "# 5분으로 나누지 않은 값을 기록한 부분. \n",
    "# D:/MultiModal/Face_z_score/Face_lean_count/backup/All_face_box_zip/Modify_box_size_all/\n",
    "\n",
    "for week in [\"1W\", \"2W\", \"3W\", \"4W\"]:\n",
    "    for group in [\"C\"]:\n",
    "        for step in [\"S1\", \"S2\", \"S3\"]:\n",
    "            # [\"S1_1\", \"S1_2\", \"S1_3\", \"S2_1\", \"S2_2\", \"S2_3\", \"S3\"]:\n",
    "            # [\"S1\", \"S2\", \"S3\"]:\n",
    "            \n",
    "            # 현재 디렉토리로 변경 \n",
    "            os.chdir(r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\05_27_box_delta_zip\\\\Rename_C\\\\\")\n",
    "            #os.chdir(r\"D:/MultiModal/Face_z_score/Face_lean_count/backup/All_face_box_zip/Modify_time\") \n",
    "            # 5m 간격으로 자른 것들 \n",
    "            # os.chdir(r\"D:/MultiModal/Face_z_score/Face_lean_count/backup/All_face_box_zip/Modify_time/Modify_time_5m\")\n",
    "            \n",
    "            #파일을 읽어옴. \n",
    "            read_data = pd.read_excel(f\"box_delta_{week}_{group}_{step}.xlsx\", index_col=0)\n",
    "           \n",
    "            # lean_4p를 저장하기 위한 리스트 선언. \n",
    "            step_data_4p = []\n",
    "        \n",
    "            # 동시에 기울어진 사람들을 카운트 하는 구간. \n",
    "            read_data['same'] = 0 \n",
    "                    \n",
    "            for i in range (len(read_data)):\n",
    "                # box_size 1~4 까지 있는 것들을 세어야 하는 것이므로. \n",
    "                #print(read_data.iloc[i, :4])\n",
    "                val_count = read_data.iloc[i, :4].value_counts()\n",
    "                # val_count 안에 있는 값이 0 이라면 0으로 초기화\n",
    "                val_count[0] = 0\n",
    "                \n",
    "                #print(read_data.iloc[i, :8])\n",
    "                #print(read_file.iloc[i, 5])\n",
    "                \n",
    "                # 최댓값을 넣어주려는 부분. \n",
    "                #print(read_data.iloc[i, 7])\n",
    "                read_data.iloc[i, 7] = val_count.max()\n",
    "            \n",
    "            same = np.array(read_data[\"same\"])\n",
    "\n",
    "            # 동시에 4명 중 N명이 기울었을 때를 세는 부분 || 모두 list 안에 들어있는 것. \n",
    "            step_data_4p = np.where(same>=4,1,0)\n",
    "            \n",
    "            # lean_4p에 맞게 데이터 값을 데이터 프레임으로 지정. \n",
    "            lean_4p = pd.DataFrame({\"lean_4p\" : step_data_4p})\n",
    "            new_df = pd.concat([read_data, lean_4p], axis=1)\n",
    "    \n",
    "            if 'same' in new_df.columns:\n",
    "                new_df.drop(['same'], axis=1, inplace=True) \n",
    "            \n",
    "            # 위치 바꿔주는 부분 넣어줄 것. \n",
    "            new_df.insert(4, 'lean_4p', new_df.pop('lean_4p'))    \n",
    "            \n",
    "            #엑셀 파일 값으로 저장하는 부분. \n",
    "            new_df.to_excel(output + f\"box_delta_{week}_{group}_{step}.xlsx\")       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lean 4p의 합계를 계산해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lean_4P 몇 개인지 볼 것. \n",
    "output = r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\backup\\All_face_box_zip\\\\05_27_box_delta_zip\\\\Lean_4p_SUM\\\\\"\n",
    "\n",
    "data = []\n",
    "for week in [\"1W\", \"2W\", \"3W\", \"4W\"]:\n",
    "    for group in [\"C\"]:\n",
    "        for step in [\"S1\", \"S2\", \"S3\"]:\n",
    "            # \"S1_1\", \"S1_2\", \"S1_3\", \"S2_1\", \"S2_2\", \"S2_3\", \n",
    "            # \"S1\", \"S2\", \"S3\"\n",
    "            os.chdir(r\"D:\\\\MultiModal\\\\Face_z_score\\\\Face_lean_count\\\\backup\\\\All_face_box_zip\\\\05_27_box_delta_zip\\\\Add_Lean_4p_A\") \n",
    "            read_data = pd.read_excel(f\"box_delta_{week}_{group}_{step}.xlsx\", index_col=0)\n",
    "        \n",
    "            result = read_data[\"lean_4p\"].sum()\n",
    "            \n",
    "            data.append(result)\n",
    "            \n",
    "            #데이터 확인해볼 것 \n",
    "            # print(data)\n",
    "\n",
    "temp_df = pd.DataFrame(data, columns=[\"SUM_LEAN_4P\"])\n",
    "os.chdir(output)\n",
    "temp_df.to_excel(\"LEAN_4P_SUM_A.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
